{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from IPython import get_ipython\n",
    "#get_ipython().magic('reset -sf') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from gensim.models import Word2Vec\n",
    "from os import path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "from timeit import default_timer as timer\n",
    "import itertools\n",
    "import csv\n",
    "import cplex\n",
    "from math import inf as infinity\n",
    "from scipy.spatial.distance import cdist\n",
    "import bisect\n",
    "from multiprocessing import Pool\n",
    "import multiprocessing\n",
    "from itertools import repeat\n",
    "from itertools import islice, groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prefix                 = path.expanduser(\"/home/mcaserta/research/nlp/data\")\n",
    "ecco_models_folder     = \"ecco_models/\"\n",
    "vocab_folder           = \"google_vocab/\"\n",
    "modelnameW2V           = \"word2vec.model.96-00.all\"\n",
    "premiumDocsXRowBase    = \"/home/mcaserta/research/nlp/ecco_code/preproc/premiumDocsXRow.csv\"\n",
    "premiumCorpusXRowBase  = \"/home/mcaserta/research/nlp/ecco_code/preproc/premiumCorpusXRow.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def setupTarget(target, model):\n",
    "    # setup target (invariant over cycle)\n",
    "    nWords = len(target)\n",
    "    demand = {key:0 for key in target}\n",
    "    for w in target:\n",
    "        demand[w] += 1\n",
    "    nD     = len(demand)\n",
    "    dem    = [val/nWords for val in demand.values()]\n",
    "    D      = model.wv[demand.keys()]\n",
    "    \n",
    "    return nD, dem, D\n",
    "\n",
    "def solveTransport2(matrixC, cap, dem, nS, nD):\n",
    "    \"\"\"\n",
    "    Solve transportation problem as an LP.\n",
    "    This is my implementation of the WMD.\n",
    "    \"\"\"\n",
    "    \n",
    "    cpx   = cplex.Cplex()\n",
    "    x_ilo = []\n",
    "    cpx.objective.set_sense(cpx.objective.sense.minimize)\n",
    "    for i in range(nS):\n",
    "        x_ilo.append([])\n",
    "        for j in range(nD):\n",
    "            x_ilo[i].append(cpx.variables.get_num())\n",
    "            #  varName = \"x.\" + str(i) + \".\" + str(j)\n",
    "            cpx.variables.add(obj   = [float(matrixC[i][j])],\n",
    "                              lb    = [0.0])\n",
    "                              #  names = [varName])\n",
    "    # capacity constraint\n",
    "    for i in range(nS):\n",
    "        index = [x_ilo[i][j] for j in range(nD)]\n",
    "        #value = [1.0]*nD\n",
    "        capacity_constraint = cplex.SparsePair(ind=index, val=[1.0]*nD)\n",
    "        #capacity_constraint = cplex.SparsePair(ind=index, val=np.ones(nD))\n",
    "        cpx.linear_constraints.add(lin_expr = [capacity_constraint],\n",
    "                                   senses   = [\"L\"],\n",
    "                                   rhs      = [cap[i]])\n",
    "\n",
    "    # demand constraints\n",
    "    for j in range(nD):\n",
    "        index = [x_ilo[i][j] for i in range(nS)]\n",
    "        #value = [1.0]*nS\n",
    "        demand_constraint = cplex.SparsePair(ind=index, val=[1.0]*nS)\n",
    "        cpx.linear_constraints.add(lin_expr = [demand_constraint],\n",
    "                                   senses   = [\"G\"],\n",
    "                                   rhs      = [dem[j]])\n",
    "    cpx.parameters.simplex.display.set(0)\n",
    "    cpx.solve()\n",
    "\n",
    "    return cpx.solution.get_objective_value()\n",
    "\n",
    "\n",
    "def wmdTransportNoLB(model, source, D, nD, dem):\n",
    "        nWords   = len(source)\n",
    "        capacity = {key:0 for key in source}\n",
    "        #  print(\"SOURCE = \", source)\n",
    "        for w in source:\n",
    "            capacity[w] += 1\n",
    "\n",
    "        nS       = len(capacity)\n",
    "        cap      = [val/nWords for val in capacity.values()]\n",
    "        try:\n",
    "            S        = model.wv[capacity.keys()]\n",
    "        except:\n",
    "            return -1\n",
    "        dd       = cdist(S,D)\n",
    "\n",
    "        # solve transportation problem\n",
    "        z = solveTransport2(dd, cap, dem, nS, nD)\n",
    "\n",
    "        return z\n",
    "    \n",
    "def wmdTransport(model, sent, D, nD, dem, lastScore):\n",
    "        source = sent.tokens\n",
    "        nWords   = len(source)\n",
    "        capacity = {key:0 for key in source}\n",
    "        #print(\"SOURCE = \", source)\n",
    "        for w in source:\n",
    "            capacity[w] += 1\n",
    "\n",
    "        nS       = len(capacity)\n",
    "        cap      = [val/nWords for val in capacity.values()]\n",
    "        try:\n",
    "            S        = model.wv[capacity.keys()]\n",
    "        except: #this might occur when the word is not in the dictionary\n",
    "            return -1\n",
    "        dd       = cdist(S,D)\n",
    "        \n",
    "        # compute lower bounds for fathoming\n",
    "        lb = np.dot(dd.min(axis=1), cap)\n",
    "        if lb >= lastScore:\n",
    "            #sent.z=-1\n",
    "            return sent\n",
    "        \n",
    "        lb = np.dot(dd.min(axis=0), dem)\n",
    "        if lb > lastScore:\n",
    "            #sent.z=-1\n",
    "            return sent\n",
    "\n",
    "        # if not pruned, solve transportation problem\n",
    "        sent.z = solveTransport2(dd, cap, dem, nS, nD)\n",
    "        \n",
    "        return sent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadW2V():\n",
    "    fullpath = path.join(prefix, ecco_models_folder)\n",
    "    fullname = fullpath + modelnameW2V\n",
    "    mW2V = Word2Vec.load(fullname)\n",
    "    mW2V.init_sims(replace=True)\n",
    "    return mW2V\n",
    "#%time loadW2V()\n",
    "global mW2V\n",
    "mW2V = loadW2V()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#target=[\"sublime\", \"modification\", \"power\"]\n",
    "target=[ \"power\", \"one\"]\n",
    "nD, dem, D = setupTarget(target, mW2V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Sentence:\n",
    "    def __init__(self):\n",
    "        self.tokens = []\n",
    "        self.z      = -1\n",
    "        self.id     = -1\n",
    "#        self.year   = -1 # not used, verify\n",
    "class Top():\n",
    "    \"\"\"\n",
    "    Data structure used to store the top N sentences matching a given target\n",
    "    sentence.\n",
    "    We store both the full sentence (untokenized) and the tokenized and\n",
    "    preprocessed sentence. We also store the previous and next sentences.\n",
    "    \"\"\"\n",
    "    def __init__(self, nTop):\n",
    "        self.score     = [-1]*nTop\n",
    "        self.idnr      = [\"\"]*nTop\n",
    "        self.year      = [\"\"]*nTop\n",
    "        self.tokenSent = [[]]*nTop\n",
    "        self.sent      = [\"\"]*nTop\n",
    "        self.prevSent  = [\"\"]*nTop\n",
    "        self.nextSent  = [\"\"]*nTop\n",
    "        self.idx       = [-1]*nTop\n",
    "        self.best      = infinity\n",
    "        self.star      = \" \"\n",
    "        self.plus      = \" \"\n",
    "            \n",
    "    def getSortedList(self):\n",
    "        return [self.score[i] for i in self.idx]\n",
    "\n",
    "def populateFirstnTop(model, tops, year, nPopulate, readerDocs, D, nD, dem):\n",
    "    # populate empty list\n",
    "    forbiddenWords = [\"one\"]\n",
    "    i = 0\n",
    "    for source in islice(readerDocs, 0, nPopulate):\n",
    "        found = False\n",
    "        for w in source:\n",
    "            if w in forbiddenWords:\n",
    "                found = True\n",
    "                break\n",
    "        if found:\n",
    "            continue\n",
    "            \n",
    "        #print(\"sentence for process \", multiprocessing.current_process().name, \" = \", source)\n",
    "        z = wmdTransportNoLB(mW2V, source, D, nD, dem)\n",
    "        tops.score[i]     = z\n",
    "        tops.tokenSent[i] = source        \n",
    "        tops.idx[i]       = i\n",
    "        tops.idnr[i]      = i\n",
    "        tops.year[i]      = year\n",
    "        i += 1\n",
    "    # sort index w.r.t. score\n",
    "    tops.idx = [x for _,x in sorted(zip(tops.score,tops.idx))]\n",
    "    return tops\n",
    "        \n",
    "def sortedInsertion(tops, sent, year, nTop):\n",
    "    #print(\"Insering\", sent.z, \"into\", tops.getSortedList())\n",
    "    #print(\"Index = \", tops.idx)\n",
    "    last = tops.idx[-1]\n",
    "    ss = [tops.score[i] for i in tops.idx]\n",
    "    ss = tops.getSortedList()\n",
    "    pos  = bisect.bisect(ss, sent.z)\n",
    "    #print(\"in position \", pos)\n",
    "    # add here information of the newly inserted item\n",
    "    # (all the other fields do not need to be changed\n",
    "    #  just move the idx value)\n",
    "    tops.score[last]      = sent.z\n",
    "    tops.idnr[last]       = sent.id\n",
    "    tops.tokenSent[last]  = sent.tokens\n",
    "    tops.year[last]       = year\n",
    "    for i in range(nTop-2, pos-1, -1):\n",
    "        tops.idx[i+1]       = tops.idx[i]\n",
    "    tops.idx[pos] = last\n",
    "    #print(\"Is sorted ? \", tops.getSortedList() == sorted(tops.score))\n",
    " \n",
    "    return tops\n",
    "\n",
    "def updateBest(tops, year, totSents, totPruned, i, totRead):\n",
    "    if tops.score[tops.idx[0]] < tops.best:\n",
    "        tops.best = tops.score[tops.idx[0]]\n",
    "        tops.star = \"*\"\n",
    "    else:\n",
    "        tops.star = \" \"\n",
    "    print(\"[{0:5.0f} secs. -{1}- {2:7d}/{3}] z* = {4:5.3f}\\t [Fathomed : {5:7d} ({6:5.3f})] {7}{8}\".format(timer()-start, year, i, totSents, tops.best, totPruned, totPruned/totRead, tops.plus, tops.star))\n",
    "    tops.plus = \" \"\n",
    "    return tops\n",
    "\n",
    "def printTops(tops):\n",
    "    for i,id in enumerate(tops.idx):\n",
    "        print(\"[{0:4d}--{1}.{2:8d}] {3:5.3f} :: {4}\".format(i, tops.year[id], tops.idnr[id], tops.score[id], tops.tokenSent[id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wmdParallel(nCores, batch, printStep, years, tops, nTop, totPruned, totRead, totSentences):\n",
    "    forbiddenWords = [\"one\"]\n",
    "    p     = Pool(nCores)\n",
    "    for year in years:\n",
    "        premiumDocsXRow   = premiumDocsXRowBase + \".\" + year\n",
    "        premiumCorpusXRow = premiumCorpusXRowBase + \".\" + year\n",
    "        totSents = totSentences[year]\n",
    "        totSents = 10000\n",
    "        print(\"Loading sentences for year {0} [{1:7d} sentences]\".format(year,totSents))\n",
    "\n",
    "        with open(premiumDocsXRow, \"r\") as fDocs:\n",
    "        #fDocs        = open(premiumDocsXRow, \"r\")\n",
    "            readerDocs   = csv.reader(fDocs)\n",
    "            nPopulate = 0\n",
    "            if year == years[0]:\n",
    "                nPopulate = min(nTop, totSents)\n",
    "                tops = populateFirstnTop(mW2V, tops, year, nPopulate, readerDocs, D, nD, dem)\n",
    "                tops = updateBest(tops, year, totSents, totPruned, nTop, nTop)\n",
    "\n",
    "            batches = batch*nCores\n",
    "            sources = []\n",
    "            initIndex = nPopulate # to recover the index of each sentence\n",
    "\n",
    "            for i,source in itertools.islice(enumerate(readerDocs), 0, totSents):\n",
    "                found = False\n",
    "                for w in source:\n",
    "                    if w in forbiddenWords:\n",
    "                        found = True\n",
    "                        break\n",
    "                if found:\n",
    "                    continue                \n",
    "                sent = Sentence()\n",
    "                sent.tokens = source\n",
    "                sent.id = nPopulate+i\n",
    "                sources.append(sent)\n",
    "\n",
    "                if i % printStep == 0:\n",
    "                    totRead += printStep\n",
    "                    tops = updateBest(tops, year, totSents, totPruned, i, totRead)\n",
    "\n",
    "                if (i+1) % batches == 0 or i==totSents-1:\n",
    "                    # divide and send\n",
    "                    nSent = len(sources)\n",
    "                    sets = np.array_split(np.arange(0,nSent,1), nCores)\n",
    "                    slicedSources = [[ sources[s] for s in myset] for myset in sets]\n",
    "                    results = p.starmap(getWMD,zip(slicedSources, repeat(tops.score[tops.idx[-1]]), repeat(D), repeat(nD), repeat(dem)) )\n",
    "\n",
    "                    for cc in range(nCores):\n",
    "                        for sent in results[cc]:\n",
    "                            if sent.z == -1:\n",
    "                                totPruned += 1\n",
    "                            else:\n",
    "                                if sent.z < tops.score[tops.idx[-1]]:\n",
    "                                    tops.plus = \"+\"\n",
    "                                    sortedInsertion(tops, sent, year, nTop)\n",
    "                    sources = []\n",
    "                    initIndex += nSent\n",
    "\n",
    "            totRead += printStep\n",
    "            tops = updateBest(tops, year, totSents, totPruned, i+1, totRead)\n",
    " \n",
    "    p.close()       \n",
    "        \n",
    "    return tops, totPruned, totRead\n",
    "\n",
    "def getWMD(sources, lastScore, D, nD, dem):\n",
    "    return [wmdTransport(mW2V, sent, D, nD, dem, lastScore) for sent in sources]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def eccoWMD(nTop=10, batch=25, nCores=4, printStep=200000):\n",
    "    \n",
    "    global start\n",
    "    global tops\n",
    "    tops      = Top(nTop)\n",
    "\n",
    "    years        = [\"1796\", \"1797\", \"1798\", \"1799\", \"1800\"]\n",
    "    #years        = [\"1796\", \"1797\"]\n",
    "    totSentences = {\"1796\":3280661, \"1797\":2945687,\"1798\":2857190, \"1799\":2622691, \"1800\":3098020 }\n",
    "\n",
    "    totPruned = 0\n",
    "    totRead   = 0\n",
    "\n",
    "    start = timer()\n",
    "    tops, totPruned, totRead = wmdParallel(nCores, batch, printStep, years, tops, nTop, totPruned, totRead, totSentences)\n",
    "\n",
    "    print(\"Total Sentences Analyzed = \", totRead, \"over a period of \", len(years), \"years in \", timer()-start, \" seconds.\")\n",
    "\n",
    "    return tops\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def retrieveSentences(topsOut, nTop):\n",
    "    # store it the \"right way\", no more pointers\n",
    "    df = pd.DataFrame({\n",
    "        'year'  : [topsOut.year[i] for i in topsOut.idx],\n",
    "        'idnr'  : [topsOut.idnr[i] for i in topsOut.idx],\n",
    "        'score' : [topsOut.score[i] for i in topsOut.idx],\n",
    "        'tokenSent' : [topsOut.tokenSent[i] for i in topsOut.idx],\n",
    "        'sent'      : ['']*nTop,\n",
    "        'prevSent'  : ['']*nTop,\n",
    "        'nextSent'  : ['']*nTop        \n",
    "    })\n",
    "    \n",
    "    df = df.sort_values(['year','idnr'])\n",
    "    #print(\"SORTED DF = \", df)\n",
    "    groups = df.groupby('year')\n",
    "    previousIndex = -1\n",
    "    # check missing: if sentence is first or last of the file, i.e., idnr=0 or nSent\n",
    "    for year, grouped_df in groups:\n",
    "        premiumCorpusXRow = premiumCorpusXRowBase + \".\" + year\n",
    "        with open(premiumCorpusXRow, \"r\") as fCorpus:\n",
    "            readerCorpus   = csv.reader(fCorpus)\n",
    "\n",
    "            currentPos = 1 # position of the header in file \n",
    "            # REM: after reading line e.g., 7, the header is positioned on line 8\n",
    "            for index,el in grouped_df.iterrows():\n",
    "                \n",
    "                position    = el.idnr-currentPos \n",
    "                currentPos  = el.idnr + 3 # each time, we move three steps\n",
    "                if position == -2:  # e.g., 10 and 11\n",
    "                    df.prevSent[index] = df.sent[previousIndex]\n",
    "                    df.sent[index]     = df.nextSent[previousIndex]\n",
    "                    df.nextSent[index] = fCorpus.readline()\n",
    "                elif position == -1: # e.g., 10 and 12\n",
    "                    df.prevSent[index] = df.nextSent[previousIndex]\n",
    "                    df.sent[index]     = fCorpus.readline()\n",
    "                    df.nextSent[index] = fCorpus.readline()                    \n",
    "                else: # e.g., 10 and 13\n",
    "                    for line in islice(fCorpus, position, position+1, 1):\n",
    "                        df.prevSent[index] = line\n",
    "                    df.sent[index]     = fCorpus.readline()\n",
    "                    df.nextSent[index] = fCorpus.readline()\n",
    "                previousIndex = index \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading sentences for year 1796 [  10000 sentences]\n",
      "[    0 secs. -1796-      10/10000] z* = 1.074\t [Fathomed :       0 (0.000)]  *\n",
      "[    0 secs. -1796-       0/10000] z* = 1.074\t [Fathomed :       0 (0.000)]   \n",
      "[    1 secs. -1796-   10000/10000] z* = 0.901\t [Fathomed :    8926 (0.022)] +*\n",
      "Loading sentences for year 1797 [  10000 sentences]\n",
      "[    1 secs. -1797-       0/10000] z* = 0.901\t [Fathomed :    8926 (0.015)]   \n",
      "[    2 secs. -1797-   10000/10000] z* = 0.898\t [Fathomed :   18065 (0.023)] +*\n",
      "Loading sentences for year 1798 [  10000 sentences]\n",
      "[    2 secs. -1798-       0/10000] z* = 0.898\t [Fathomed :   18065 (0.018)]   \n",
      "[    2 secs. -1798-   10000/10000] z* = 0.898\t [Fathomed :   27259 (0.023)] + \n",
      "Loading sentences for year 1799 [  10000 sentences]\n",
      "[    2 secs. -1799-       0/10000] z* = 0.898\t [Fathomed :   27259 (0.019)]   \n",
      "[    3 secs. -1799-   10000/10000] z* = 0.877\t [Fathomed :   36517 (0.023)] +*\n",
      "Loading sentences for year 1800 [  10000 sentences]\n",
      "[    3 secs. -1800-       0/10000] z* = 0.877\t [Fathomed :   36517 (0.020)]   \n",
      "[    3 secs. -1800-   10000/10000] z* = 0.877\t [Fathomed :   45769 (0.023)] + \n",
      "Total Sentences Analyzed =  2000000 over a period of  5 years in  3.2739815449999696  seconds.\n"
     ]
    }
   ],
   "source": [
    "#%lprun -f wmdTransport \n",
    "nTop = 10\n",
    "tops = eccoWMD(nTop=nTop, batch=25, nCores=8)\n",
    "df = retrieveSentences(tops, nTop)\n",
    "df.to_csv(\"solution.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idnr</th>\n",
       "      <th>nextSent</th>\n",
       "      <th>prevSent</th>\n",
       "      <th>score</th>\n",
       "      <th>sent</th>\n",
       "      <th>tokenSent</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3077</td>\n",
       "      <td>\"I Continually haunting the offices of the war...</td>\n",
       "      <td>\"PART I. H time ( 98) time and attention were ...</td>\n",
       "      <td>0.922747</td>\n",
       "      <td>\"ment, fortune, and power.\"\\n</td>\n",
       "      <td>[ment, fortune, power]</td>\n",
       "      <td>1796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9136</td>\n",
       "      <td>\"The minds of the people are already angered w...</td>\n",
       "      <td>\"It is in vain to dissemble that this country ...</td>\n",
       "      <td>0.900644</td>\n",
       "      <td>Mr. Pitt has it in his power to save himself a...</td>\n",
       "      <td>[power, save, empire]</td>\n",
       "      <td>1796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>248</td>\n",
       "      <td>\"By Power, is meant 4 Almighty abilit 6. to co...</td>\n",
       "      <td>\"41. minion of both, because &amp;#x00B0; Prayer i...</td>\n",
       "      <td>0.898427</td>\n",
       "      <td>\"q all Dominion, Power, and Glory.\"\\n</td>\n",
       "      <td>[dominion, power, glory]</td>\n",
       "      <td>1797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1549</td>\n",
       "      <td>The coefficient of each term is obtained by mu...</td>\n",
       "      <td>\"On the contrary, b is wanting in the first te...</td>\n",
       "      <td>0.912033</td>\n",
       "      <td>\"In all the terms, the sum of the exponents of...</td>\n",
       "      <td>[terms, sum, equal, power]</td>\n",
       "      <td>1797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4570</td>\n",
       "      <td>\"Gaolers or printer of the Gazette not complyi...</td>\n",
       "      <td>\"with treble colts; the debtor&amp;#x0027; s right...</td>\n",
       "      <td>0.933549</td>\n",
       "      <td>\"Power of leasing lands yelled in assignee,.\"\\n</td>\n",
       "      <td>[power, lands, assignee]</td>\n",
       "      <td>1798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7862</td>\n",
       "      <td>\"alone belongs all the higher pursuits, of kno...</td>\n",
       "      <td>\"indeed everything is guided by these, a few f...</td>\n",
       "      <td>0.955693</td>\n",
       "      <td>\"belongs all; power and authority, public and ...</td>\n",
       "      <td>[belongs, power, authority, public, private]</td>\n",
       "      <td>1798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9495</td>\n",
       "      <td>\"Wre would be glad to see the persons condesce...</td>\n",
       "      <td>\"How came their frame to be different from, na...</td>\n",
       "      <td>0.962934</td>\n",
       "      <td>\"If so, why have they more impediments, and le...</td>\n",
       "      <td>[impediments, less, power, obedience]</td>\n",
       "      <td>1798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2988</td>\n",
       "      <td>\"IT is a singular circumstance in the history ...</td>\n",
       "      <td>\"The house of peers have an officer called a c...</td>\n",
       "      <td>0.883100</td>\n",
       "      <td>Its legislative Power aidt Privileges.\\n</td>\n",
       "      <td>[legislative, power, privileges]</td>\n",
       "      <td>1799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4583</td>\n",
       "      <td>But you know that ours are not kings by eletio...</td>\n",
       "      <td>\"What racks must the man, who has these exampl...</td>\n",
       "      <td>0.877173</td>\n",
       "      <td>\"For nations, who have the power of eleeting k...</td>\n",
       "      <td>[nations, power, kings, also, power, binding]</td>\n",
       "      <td>1799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4115</td>\n",
       "      <td>\"And such powers and conditions may be execute...</td>\n",
       "      <td>\"Nor to estates to her on condition to sell, i...</td>\n",
       "      <td>0.959218</td>\n",
       "      <td>\"Or with a power annexed to them, ibid.\"\\n</td>\n",
       "      <td>[power, annexed, ibid]</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idnr                                           nextSent  \\\n",
       "5  3077  \"I Continually haunting the offices of the war...   \n",
       "3  9136  \"The minds of the people are already angered w...   \n",
       "2   248  \"By Power, is meant 4 Almighty abilit 6. to co...   \n",
       "4  1549  The coefficient of each term is obtained by mu...   \n",
       "6  4570  \"Gaolers or printer of the Gazette not complyi...   \n",
       "7  7862  \"alone belongs all the higher pursuits, of kno...   \n",
       "9  9495  \"Wre would be glad to see the persons condesce...   \n",
       "1  2988  \"IT is a singular circumstance in the history ...   \n",
       "0  4583  But you know that ours are not kings by eletio...   \n",
       "8  4115  \"And such powers and conditions may be execute...   \n",
       "\n",
       "                                            prevSent     score  \\\n",
       "5  \"PART I. H time ( 98) time and attention were ...  0.922747   \n",
       "3  \"It is in vain to dissemble that this country ...  0.900644   \n",
       "2  \"41. minion of both, because &#x00B0; Prayer i...  0.898427   \n",
       "4  \"On the contrary, b is wanting in the first te...  0.912033   \n",
       "6  \"with treble colts; the debtor&#x0027; s right...  0.933549   \n",
       "7  \"indeed everything is guided by these, a few f...  0.955693   \n",
       "9  \"How came their frame to be different from, na...  0.962934   \n",
       "1  \"The house of peers have an officer called a c...  0.883100   \n",
       "0  \"What racks must the man, who has these exampl...  0.877173   \n",
       "8  \"Nor to estates to her on condition to sell, i...  0.959218   \n",
       "\n",
       "                                                sent  \\\n",
       "5                      \"ment, fortune, and power.\"\\n   \n",
       "3  Mr. Pitt has it in his power to save himself a...   \n",
       "2              \"q all Dominion, Power, and Glory.\"\\n   \n",
       "4  \"In all the terms, the sum of the exponents of...   \n",
       "6    \"Power of leasing lands yelled in assignee,.\"\\n   \n",
       "7  \"belongs all; power and authority, public and ...   \n",
       "9  \"If so, why have they more impediments, and le...   \n",
       "1           Its legislative Power aidt Privileges.\\n   \n",
       "0  \"For nations, who have the power of eleeting k...   \n",
       "8         \"Or with a power annexed to them, ibid.\"\\n   \n",
       "\n",
       "                                       tokenSent  year  \n",
       "5                         [ment, fortune, power]  1796  \n",
       "3                          [power, save, empire]  1796  \n",
       "2                       [dominion, power, glory]  1797  \n",
       "4                     [terms, sum, equal, power]  1797  \n",
       "6                       [power, lands, assignee]  1798  \n",
       "7   [belongs, power, authority, public, private]  1798  \n",
       "9          [impediments, less, power, obedience]  1798  \n",
       "1               [legislative, power, privileges]  1799  \n",
       "0  [nations, power, kings, also, power, binding]  1799  \n",
       "8                         [power, annexed, ibid]  1800  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext line_profiler\n",
    "#%lprun -f retrieveSentences retrieveSentences(tops,nTop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!python -m line_profiler script_to_profile.py.lprof"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
